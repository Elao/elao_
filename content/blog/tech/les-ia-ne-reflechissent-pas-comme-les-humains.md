---
title: 'Les IA g√©n√©ratives ne r√©fl√©chissent pas comme les humains'
date: '2024-03-28' # Au format YYYY-MM-DD
lastModified: ~ # Au format YYYY-MM-DD. Pour indiquer explicitement qu'un article a √©t√© mis √† jour
description: "D√©couvrez √† travers cet article le fonctionnement des IA et plus sp√©cifiquement des mod√®les de langage"
authors: [equentin] # (multiple accept√©s)
tableOfContent: false # `true` pour activer ou `3` pour lister les titres sur 3 niveaux.
tags: [ia, chatgpt, llm, prompt]
thumbnail: 
#banner: images/posts/headers/arc-max-quand-l-ia-simplifie-notre-navigation-sur-le-web.jpg # Uniquement si diff√©rent de la minitature (thumbnail)
#credit: { name: 'Thomas Jarrand', url: 'https://unsplash.com/@tom32i' } # Pour cr√©diter la photo utilis√©e en miniature
tweetId: '' # Ajouter l'id du Tweet apr√®s publication.
outdated: false # `true` pour marquer un article comme obsol√®te ou une cha√Æne de caract√®re pour un message sp√©cifique √† afficher
---

√Ä la sortie de ChatGPT, nous avons √©t√© nombreux¬∑se √† tester cet outil qui est apparu comme une nouvelle attraction r√©volutionnaire. Nous avons commenc√© √† lui poser des questions, plus ou moins pr√©cises, √† √©changer avec lui, √† le tester et √† tenter de d√©couvrir ses limites. 

Au sein de l‚Äôagence, nous avons √©t√© quelques uns √† nous int√©resser de plus pr√®s √† ChatGPT mais surtout au fonctionnement de ces IA g√©n√©ratives afin de mieux les appr√©hender. Comprendre le m√©canisme de ces outils nous a ainsi permis d‚Äôaller plus loin dans leur utilisation et de mesurer l‚Äôint√©r√™t qu‚Äôils peuvent avoir dans notre quotidien professionnel.

√Ä travers notre veille personnelle, notre participation √† des conf√©rences, √† nos √©tudes sur des lectures sp√©cialis√©es, nous avons r√©alis√© une chose essentielle :  l**es IA ne poss√®dent pas une capacit√© de r√©flexion similaire √† celle des √™tres humains . Ce sont avant tout des outils entra√Æn√©s, capables d‚Äôassimiler des donn√©es et de compiler des informations.** En partant de ce postulat, le fonctionnement de ces assistants et la mani√®re de cr√©er des prompts nous est apparu plus clair, notamment pour la cr√©ation de notre produit Amabla.  

# De mani√®re tr√®s simple, comment fonctionne une IA g√©n√©rative ?

L‚Äôunivers de l‚Äôintelligence artificielle est pr√©sent depuis d√©j√† de nombreuses ann√©es (d√®s les ann√©es 50). Avec le d√©veloppement de l‚Äôinformatique et son d√©ploiement aupr√®s du grand public, les IA ont commenc√© √† conna√Ætre un succ√®s important dans les ann√©es 2000, notamment avec l‚Äôune des avanc√©es majeure de l‚ÄôIA : le **machine learning** (ou l‚Äôart pour les machines d‚Äôapprendre par elles-m√™mes en analysant des donn√©es et en am√©liorant leurs performances au fil du temps). C‚Äôest dans les ann√©es 2020 que nous allons voir appara√Ætre la notion de **mod√®le de fondation** (capable de comprendre et de g√©n√©rer du contenu) connaissant une popularisation grandissante avec l‚Äôarriv√©e de l‚Äôoutil ChatGPT.

# Comment r√©sumer simplement le fonctionnement d‚Äôune IA g√©n√©rative bas√©e sur les mod√®les de langage (ou LLM) ? 

Le principe des **LLM** (Large Language Models) repose sur l‚Äôutilisation de **r√©seaux de neurones** √† grande √©chelle pour analyser, comprendre et g√©n√©rer du texte. Ces syst√®mes sont entra√Æn√©s sur des grands corpus de texte leur permettant de comprendre des mod√®les linguistiques, des structures grammaticales, des associations de mots et des nuances de langage. 

Les LLM sont √©galement dot√©s d‚Äôune certaine sp√©cificit√© : la **pr√©diction**. En effet, les LLM fonctionnent en pr√©disant le mot suivant dans une s√©quence de mots, en se basant sur les mots pr√©c√©dents. Cela leur permet de concevoir des contenus coh√©rents et contextuellement pertinents. 

Pour comprendre un peu plus pr√©cis√©ment le fonctionnement des IA g√©n√©ratives sans entrer dans des d√©tails trop techniques, il est important de se focaliser sur plusieurs points d‚Äôattentionüëá

# Comprendre leur fonctionnement

## Les IA g√©n√©ratives ne nous r√©pondent pas en langage naturel 

Lorsque nous formulons notre prompt, l‚ÄôIA ne va pas prendre en consid√©ration les mots en tant que tel, mais va, via le processus de tokenisation, convertir le texte en une s√©rie de vecteurs num√©riques. Le texte va alors √™tre transform√© en **token**. Le principe des tokens est primordial pour les mod√®les d‚ÄôIA bas√©s sur le langage car ils permettent de convertir le texte en **donn√©es structur√©es que les algorithmes peuvent traiter**. 

Plus concr√®tement, les LLM ne vont pas travailler directement sur les mots en eux-m√™mes, mais vont les d√©composer. G√©n√©ralement, un token correspond √† ¬æ d‚Äôun mot. 

<figure>
    <img src="content/images/blog/2024/ia/nbr-tokens.png" alt="Calculer le nombre de token sur une phrase" width="250">
    <figcaption>
      <span class="figure__legend">Calculer le nombre de token sur une phrase</span>
    </figcaption>
</figure>

!!! "
Si vous souhaitez comprendre le fonctionnement de tok√©nisation et tester vos propres contenus, OpenAI propose un outil qui comptabilise votre phrase en tokens (en fonction du mod√®le - ChatGPT 3 OU 4) https://platform.openai.com/tokenizer

Chaque LLM poss√®de son propre fonctionnement de tokenisation et est capable de g√©n√©rer plus ou moins de token. Par exemple, actuellement **ChatGPT 4** (OpenAI) peut g√©n√©rer en une seule fois (ce qu‚Äôon appelle la fen√™tre de contexte) 8 000 tokens, soit 6 000 mots. √Ä l‚Äôinverse, **Gemini** (Google), peut g√©n√©rer 32 000 tokens, soit 24 000 mots. 

## Les IA g√©n√©ratives adaptent les mots √† leur propre langage 

Pour rappel, les mod√®les d‚ÄôIA g√©n√©ratives, se reposant sur des principes math√©matiques, ne sont pas capables de comprendre un mot en langage naturel. Elles vont donc devoir trouver un moyen de le transformer dans leur  langage √† elles. Pour cela, elles vont transformer un mot en un vecteur. 

Avec ce principe l√†, elles vont pouvoir traiter le terme et donner une suite logique √† ce dernier. Bien qu‚Äôun autre √©l√©ment va intervenir afin de produire un contenu encore plus pr√©cis. 

## Les IA g√©n√©ratives analysent le sens des mots

Afin de pouvoir anticiper le prochain mot et cr√©er un contenu coh√©rent, les IA vont devoir positionner un terme dans son ensemble dans le but de lui donner du sens, via un syst√®me de coordonn√©es. C‚Äôest ce que l‚Äôon appelle l‚Äô**embedding**. 

Prenons l‚Äôexemple d√©velopp√© par Science √âtonnante**. Nous souhaitons positionner le mot ‚Äúchat‚Äù. Nous prenons deux dimensions en compte : sa domestication et sa taille. 
Ainsi, nous positionnons le chat (bien domestiqu√© et plut√¥t petit) sur un graphique. Le chien va appara√Ætre √† c√¥t√© (car encore plus domestiqu√© et un peu plus grand). Si nous souhaitons positionner le lynx, ce dernier va appara√Ætre au-dessus du chat (car plus sauvage et plus grand), de m√™me pour le loup. Ainsi, on va attribuer √† chacun de ces termes deux nombres, comprenant donc deux dimensions. Cela va nous permettre de positionner un terme dans son ensemble. 

<figure>
    <img src="content/images/blog/2024/ia/embedding.png" alt="exemple du syst√®me d'embedding" width="250">
    <figcaption>
      <span class="figure__legend">Exemple du syst√®me d'embedding</span>
    </figcaption>
</figure>

Dans cet exemple, nous prenons en compte 2 nombres pour 2 dimensions, mais il faut bien comprendre que pour des textes plus cons√©quents, cela ne sera pas suffisant. Il faudra alors plus de dimension, g√©n√©ralement 300, afin de placer le mot dans ‚Äúl‚Äôespace des significations‚Äù.

Avec ce principe, les IA g√©n√©ratives sont capables de pr√©voir la suite des mots de mani√®re plus probable et donc de concevoir une r√©ponse plus pouss√©e, plus coh√©rente. 

# L'essentiel √† retenir 

Comme l‚Äôindique Flavien Chervet dans son ouvrage *Hyperprompt - Ma√Ætriser l‚Äôart du prompt engineering*, il faut ‚Äú*comprendre que les LLM ne r√©pondent pas aux demandes de l‚Äôutilisateur en ‚Äúr√©fl√©chissant*‚Äù √† la r√©ponse pertinente. Ils prennent la demande de l‚Äôutilisateur comme une nouvelle donn√©e, et tentent de pr√©dire les prochains mots les plus probables par rapport √† cette demande.‚Äù

Autrement dit, le mod√®le ne cherche pas √† dire quelque chose de vrai, il n‚Äôa pas cette dimension de v√©rit√©. Il cherche √† proposer quelque chose de plausible par rapport √† ce qu‚Äôil a pu ‚Äúapprendre‚Äù durant ses phases d‚Äôentra√Ænement.*** 

Il est important de saisir ce fonctionnement afin de pouvoir r√©aliser des prompts percutants qui vous permettront de maximiser l‚Äôapport des IA g√©n√©ratives dans votre contexte m√©tier. Ma√Ætriser l‚Äôart du prompting vous permettra d‚Äô√™tre plus efficace dans vos t√¢ches quotidiennes. 

Chez Elao, nous avons mesur√© l‚Äôimpact que les IA g√©n√©ratives pouvaient avoir dans nos m√©tiers et nous avons souhait√© travailler sur une solution adapt√©e au contexte de chacun : regrouper dans un seul et m√™me outil tous les assistants dont vous avez besoin. Vous pouvez ainsi cr√©er vos assistants sur-mesure ou utiliser des mod√®les pr√©-√©tablis, afin de vous accompagner dans vos t√¢ches hebdomadaires et vous d√©gager du temps sur les sujets pour lesquels vous avez une v√©ritable valeur ajout√©e. Mais pour cela, il nous semblait essentiel de vous partager le fonctionnement des IA, afin que vous puissiez profiter pleinement de cette solution. 

Si vous souhaitez en savoir plus sur Amabla, rendez-vous sur https://www.amabla.com ou [contactez nous](https://www.elao.com/contact). 

# Sources

- Hyperprompt - Ma√Ætriser l'art du prompt engineering de Flavien CHERVET
- [Ce qui se cache derri√®re ChatGPT](https://www.youtube.com/watch?v=CsQNF9s78Nc ) - Science √âtonnante 
- [Comment les IA font-elles pour comprendre notre langue ?](https://www.youtube.com/watch?v=7ell8KEbhJo ) - Science √âtonnante

